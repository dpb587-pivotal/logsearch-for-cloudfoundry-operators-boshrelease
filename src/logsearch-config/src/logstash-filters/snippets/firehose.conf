if [syslog_program] == "doppler" {
  json {
    source => "[@message]"
    target => "parsed_json"
    add_tag => [ "firehose" ]
  }

  mutate {
    rename => {
      "[parsed_json][deployment]" => "[@source][deployment]"
      "[parsed_json][job]" => "[@source][job]"
      "[parsed_json][ip]" => "[@source][ip]"
      "[parsed_json][event_type]" => "[@type]"
      "syslog_program" => "[@source][program]"
      "syslog_hostname" => "[@source][host]"
    }
  }

  if [@type] == "ValueMetric" {
    date {
      match => [ "[parsed_json][time]", "ISO8601"]
      target => "@timestamp"
    }
    mutate {
      rename => {
        "[parsed_json]" => "ValueMetric"
        "[ValueMetric][level]" => "@level"
        "[ValueMetric][event_type]" => "@type"
        "[ValueMetric][index]" => "[@source][index]"
      }
      remove_field => [
        "[ValueMetric][event_type]",
        "[ValueMetric][msg]",
        "[ValueMetric][cf_origin]",
        "[ValueMetric][time]"
      ]
    }

  } else if [@type] == "ContainerMetric" {
    date {
      match => [ "[parsed_json][time]", "ISO8601"]
      target => "@timestamp"
    }
    mutate {
      rename => {
        "[parsed_json]" => "ContainerMetric"
        "[ContainerMetric][cf_app_id]" => "[cf][app_id]"
        "[ContainerMetric][cf_app_name]" => "[cf][app_name]"
        "[ContainerMetric][cf_org_id]" => "[cf][org_id]"
        "[ContainerMetric][cf_org_name]" => "[cf][org_name]"
        "[ContainerMetric][cf_space_id]" => "[cf][space_id]"
        "[ContainerMetric][cf_space_name]" => "[cf][space_name]"
        "[ContainerMetric][event_type]" => "@type"
        "[ContainerMetric][level]" => "@level"
        "[ContainerMetric][instance_index]" => "[@source][index]"
      }
      remove_field => [
        "[ContainerMetric][event_type]",
        "[ContainerMetric][msg]",
        "[ContainerMetric][origin]",
        "[ContainerMetric][time]",
        "[ContainerMetric][cf_origin]"
      ]
    }

  } else if [@type] == "CounterEvent" {
    date {
      match => [ "[parsed_json][time]", "ISO8601"]
      target => "@timestamp"
    }
    mutate {
      rename => {
        "[parsed_json]" => "CounterEvent"
        "[CounterEvent][level]" => "@level"
        "[CounterEvent][event_type]" => "@type"
        "[CounterEvent][index]" => "[@source][index]"
      }
      remove_field => [
        "[CounterEvent][level]",
        "[CounterEvent][cf_origin]",
        "[CounterEvent][msg]",
        "[CounterEvent][event_type]",
        "[@message]"
      ]
    }

  } else if [@type] == "LogMessage" {
    mutate {
      rename => {
        "[parsed_json]" => "LogMessage"
        "[LogMessage][cf_app_id]" => "[cf][app_id]"
        "[LogMessage][cf_app_name]" => "[cf][app_name]"
        "[LogMessage][cf_org_id]" => "[cf][org_id]"
        "[LogMessage][cf_org_name]" => "[cf][org_name]"
        "[LogMessage][cf_space_id]" => "[cf][space_id]"
        "[LogMessage][cf_space_name]" => "[cf][space_name]"
        "[LogMessage][msg]" => "[@message]"
        "[LogMessage][event_type]" => "@type"
        "[LogMessage][level]" => "@level"
        "[LogMessage][source_instance]" => "[@source][index]"
      }
    }
    # Capture nanoseconds as @timestamp_ns from UNIX timestamps with nanosecond precision - eg, from 1458655387.327962286 store @timestamp_ns=962286
    ruby {
      code => '
        event["LogMessage"]["timestamp"], event["@timestamp_ns"] = event["LogMessage"]["timestamp"].to_s.scan(/.{1,13}/).map(&:to_i)
      '
    }
    date {
      match => [ "[LogMessage][timestamp]", "UNIX_MS"]
      target => "@timestamp"
    }
    mutate {
      remove_field => [
        "[LogMessage][origin]",
        "[LogMessage][cf_origin]",
        "[LogMessage][time]",
        "[LogMessage][timestamp]"
      ]
    }
  } else {
    mutate {
      remove => [ "parsed_json" ]
    }
  }

  mutate {
    uppercase => [ "@level" ]
  }

}
